server:
  base_url:
  request_timeout: 120
job:
  model:
    provider: vllm
    name: Qwen/Qwen3-8B
    parameters:
      tensor_parallel_size: 2
      system_prompt: |
        You are a web search assistant. Use tools sparingly and cite sources.
  source:
    dataset: gaia-benchmark/GAIA
    split: train[0:32]
    field: Question
  generation: 
    max_batch_size: 2
    max_turns: 8
    parameters:
      temperature: 0.7
      top_p: 0.9
      max_tokens: 4096
    output:
      mode: "upload_hf"