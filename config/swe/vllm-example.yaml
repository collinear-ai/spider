# Example config for SWE trajectory generation with vLLM
# Copy this file and modify for your setup

scaffold:
  type: openhands                    # Scaffold name: "openhands"
  output_dir: "./trajectories"       # Where to save trajectories

  # Dataset configuration
  dataset: "SWE-bench/SWE-smith"
  split: "train"
  max_instances: 1000  # Start small for testing
  # instance_filter: "conan-io__conan.*"  # Optional: filter by repo

  # Agent configuration
  agent_class: "CodeActAgent"
  max_iterations: 150

  llm_model: "openai/Qwen/Qwen3-Coder-30B-A3B-Instruct"  
  llm_base_url: "http://localhost:8000/v1"  # vLLM endpoint
  llm_api_key: "dummy"  # vLLM doesn't require authentication
  # Optional temperature override (null uses provider default)
  temperature: null

  # Alternative providers:
  # 
  # Fireworks AI:
  # llm_model: "accounts/fireworks/models/llama-v3p1-70b-instruct"
  # llm_base_url: "https://api.fireworks.ai/inference/v1"
  # llm_api_key_env: "FIREWORKS_API_KEY"
  #
  # Together.ai:
  # llm_model: "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo"
  # llm_base_url: "https://api.together.xyz/v1"
  # llm_api_key_env: "TOGETHER_API_KEY"
  #
  # OpenAI:
  # llm_model: "gpt-4o"
  # llm_api_key_env: "OPENAI_API_KEY"
  # (no llm_base_url needed for OpenAI)

  # Parallel processing
  num_workers: 8  

  # Performance tuning
  max_retries: 3
  timeout_seconds: 1800

  # HuggingFace upload (automatic after generation)
  hf_repo_id: collinear-ai/spider_openhands_sft_generations_qwen3_coder_30b  # Disabled - set to enable upload
  hf_private: true
  # hf_config_name: "qwen2.5-coder-32b-swe-smith"  # Optional: auto-generated if not specified

  # Output directory
  eval_output_dir: "trajectories"

