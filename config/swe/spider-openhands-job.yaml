# Example Spider job config for SWE trajectory generation using OpenHands scaffold
# This integrates SWE SFT generation into Spider's job system

server:
  base_url: http://localhost:9000
  api_key: 
  request_timeout: 600

job:
  # Model config (not used for scaffold jobs, but required by JobConfig)
  model:
    provider: "vllm"
    name: "dummy"
  
  # Source: SWE task dataset
  source:
    dataset: "SWE-bench/SWE-smith"  # HuggingFace dataset name
    split: "train"                   # Dataset split
    field: null                      # Not used for scaffold jobs
  
  # Generation: Use scaffold instead of model generation
  generation:
    scaffold:
      type: "openhands"              # Scaffold type
      agent_class: "CodeActAgent"    # OpenHands agent class
      max_iterations: 50             # Max iterations per task
      
      # LLM configuration (choose one):
      # Option 1: Use model string directly
      llm_model: "gpt-4o"            # Your LLM model name
      llm_api_key: null              # API key (or set via environment variable)
      llm_base_url: null             # Base URL (optional, for custom providers)
      
      # Examples:
      # - OpenAI: llm_model="gpt-4o", llm_api_key="sk-...", llm_base_url=null
      # - Anthropic: llm_model="anthropic/claude-3.5-sonnet-20241022", llm_api_key="sk-ant-...", llm_base_url=null
      # - Fireworks: llm_model="accounts/fireworks/models/llama-v3-70b-instruct", llm_api_key="...", llm_base_url="https://api.fireworks.ai/inference/v1"
      # - Together: llm_model="meta-llama/Llama-3-70b-chat-hf", llm_api_key="...", llm_base_url="https://api.together.xyz/v1"
      # - vLLM: llm_model="mistralai/Mistral-7B-Instruct-v0.2", llm_api_key="dummy", llm_base_url="http://localhost:8000/v1"
      
      # Option 2: Use OpenHands config name (from config.toml)
      # llm_config_name: "llm.eval_gpt4_1106_preview"
      
      # Execution configuration
      num_workers: 1                 # Parallel workers
      timeout_seconds: 3600         # 1 hour per instance
      max_retries: 5                 # Max retries on failure
      
      # Scaffold-specific options
      scaffold_specific:
        enable_browser: false
        enable_llm_editor: false
        runtime: "docker"
        platform: "linux/amd64"
        remote_runtime_resource_factor: 1
    
    # These are ignored when scaffold is used
    max_batch_size: null             # Use scaffold's max_instances instead
    max_turns: null
  
  # Output configuration
  output:
    mode: "upload_hf"                # Upload to HuggingFace
    hf:
      repo_id: "your-org/swe-trajectories-openhands"  # Your HF repo
      repo_type: "dataset"
      private: false
    # Or use "return" mode to get results directly:
    # mode: "return"
  
  # Optional metadata
  metadata:
    description: "SWE trajectory generation using OpenHands scaffold"
    dataset: "SWE-bench/SWE-smith"

